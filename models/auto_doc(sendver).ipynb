{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40067c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: torch in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pillow in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (12.0.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (4.12.0.88)\n",
      "Requirement already satisfied: scipy in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (1.16.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (2.2.6)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (0.6.7)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (2.1.2)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (1.4.0)\n",
      "Requirement already satisfied: ninja in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from easyocr) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from scikit-image->easyocr) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from scikit-image->easyocr) (2025.10.16)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ehjun\\documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\capston\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install easyocr sentence-transformers transformers torch torchvision opencv-python pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26502ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ì§€ì • ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë”© ì¤‘...\n",
      "  - MPNet ë¬¸ì¥ ì„ë² ë”© ë¡œë”©...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n",
      "ğŸ¯ ìµœì¢… íŒì •: ì¼ë°˜ ë¬¸ì„œ âŒ\n",
      "  - base similarity: 0.5314\n",
      "  - rule_score     : 0.4814\n",
      "  - keyword hits   : 0\n",
      "  - matched sent   : ë¬¸ì„œí™•ì¸ë²ˆí˜¸ 1761 2836 1342 6760 ì§„ ë³¸ 2025 10 24 14 26.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import easyocr\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class ChildcareDocumentClassifier:\n",
    "    def __init__(self, similarity_threshold: float = 0.70):\n",
    "        print(\"ğŸ“¥ ì§€ì • ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "        print(\"  - MPNet ë¬¸ì¥ ì„ë² ë”© ë¡œë”©...\")\n",
    "\n",
    "        self.mpnet_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        )\n",
    "        self.mpnet_model = AutoModel.from_pretrained(\n",
    "            \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        )\n",
    "        self.mpnet_model.eval()\n",
    "\n",
    "        self.threshold = similarity_threshold\n",
    "        print(\"âœ… ëª¨ë“  ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "\n",
    "        # OCR ë¦¬ë” (EasyOCR, í•œÂ·ì˜)\n",
    "        self.ocr_reader = easyocr.Reader([\"ko\", \"en\"], gpu=False)\n",
    "\n",
    "    # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    def extract_text_mpnet_chandra(self, image_path: str) -> str:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        result = self.ocr_reader.readtext(np.array(image))\n",
    "        text = \" \".join([txt for _, txt, conf in result if conf > 0.3])\n",
    "        return text.strip()\n",
    "\n",
    "    # MPNet ë¬¸ì¥ ì„ë² ë”©\n",
    "    def mpnet_encode(self, sentences: list) -> torch.Tensor:\n",
    "        encoded_input = self.mpnet_tokenizer(\n",
    "            sentences,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=384,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_output = self.mpnet_model(**encoded_input)\n",
    "            embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "        return embeddings\n",
    "\n",
    "    # OCR í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì •ë¦¬\n",
    "    def preprocess_sentences(self, text: str) -> list:\n",
    "        text = re.sub(r\"[^\\w\\sê°€-í£\\.!?0-9]\", \" \", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        text = re.sub(r\"(ìŠµë‹ˆë‹¤\\.|ì…ë‹ˆë‹¤\\.|ë‹¤\\.|ìš”\\.)\", r\"\\1<SPLIT>\", text)\n",
    "        text = re.sub(r\"([\\.!?])\", r\"\\1<SPLIT>\", text)\n",
    "\n",
    "        sentences = text.split(\"<SPLIT>\")\n",
    "        return [s.strip() for s in sentences if len(s.strip()) > 5]\n",
    "\n",
    "    # ê¸°ì¤€ ì„ë² ë”© 1ê°œì™€ ë¬¸ì„œ ì„ë² ë”© ì—¬ëŸ¬ ê°œì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    def compute_mpnet_similarity(\n",
    "        self, ref_embedding: torch.Tensor, doc_embeddings: torch.Tensor\n",
    "    ) -> tuple:\n",
    "        similarities = torch.nn.functional.cosine_similarity(\n",
    "            ref_embedding.unsqueeze(0),\n",
    "            doc_embeddings,\n",
    "            dim=1,\n",
    "        )\n",
    "        max_idx = similarities.argmax()\n",
    "        return float(similarities[max_idx]), max_idx\n",
    "\n",
    "    # ê¸°ë³¸ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ (thresholdë§Œ ì‚¬ìš©)\n",
    "    def classify_childcare_document(self, image_path: str, reference_sentences: list) -> dict:\n",
    "        # 1) OCR + ë¬¸ì¥ ë¶„ë¦¬\n",
    "        raw_text = self.extract_text_mpnet_chandra(image_path)\n",
    "        doc_sentences = self.preprocess_sentences(raw_text)\n",
    "\n",
    "        if len(doc_sentences) == 0:\n",
    "            return {\"verdict\": False, \"reason\": \"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨\"}\n",
    "\n",
    "        # 2) ê¸°ì¤€ ë¬¸ì¥ + ë¬¸ì„œ ë¬¸ì¥ ì„ë² ë”©\n",
    "        all_sentences = reference_sentences + doc_sentences\n",
    "        all_embeddings = self.mpnet_encode(all_sentences)\n",
    "\n",
    "        ref_embeddings = all_embeddings[: len(reference_sentences)]\n",
    "        doc_embeddings = all_embeddings[len(reference_sentences) :]\n",
    "\n",
    "        # 3) ê° ê¸°ì¤€ ë¬¸ì¥ë³„ ìµœê³  ìœ ì‚¬ë„\n",
    "        best_matches = []\n",
    "        for i, ref_emb in enumerate(ref_embeddings):\n",
    "            score, doc_idx = self.compute_mpnet_similarity(ref_emb, doc_embeddings)\n",
    "            best_matches.append(\n",
    "                {\n",
    "                    \"ref_idx\": i,\n",
    "                    \"score\": float(score),\n",
    "                    \"matched_sentence\": doc_sentences[doc_idx],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        max_match = max(best_matches, key=lambda x: x[\"score\"])\n",
    "        verdict = max_match[\"score\"] >= self.threshold\n",
    "\n",
    "        return {\n",
    "            \"verdict\": verdict,\n",
    "            \"max_confidence\": round(max_match[\"score\"], 4),\n",
    "            \"best_ref_idx\": max_match[\"ref_idx\"],\n",
    "            \"matched_sentence\": max_match[\"matched_sentence\"],\n",
    "            \"total_sentences\": len(doc_sentences),\n",
    "            \"all_scores\": {f\"ref_{i}\": m[\"score\"] for i, m in enumerate(best_matches)},\n",
    "            \"reference_sentences\": reference_sentences,\n",
    "            \"raw_text\": raw_text,\n",
    "        }\n",
    "\n",
    "\n",
    "# ----------------- ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ ë³´ì • -----------------\n",
    "\n",
    "KEYWORDS = [\"ë³´ìœ¡êµì‚¬\", \"ë³´ìœ¡\", \"ì˜ìœ ì•„ë³´ìœ¡ë²•\", \"ë³´ìœ¡êµì‚¬ìê²©ì¦\", \"ìœ ì¹˜ì›\", \"ìœ ì•„êµìœ¡ë²•\", \"êµìœ¡ë²•\",\"ìœ ì•„\",\"ì˜ìœ ì•„\"]\n",
    "\n",
    "\n",
    "def classify_childcare_with_rules(\n",
    "    classifier: ChildcareDocumentClassifier,\n",
    "    image_path: str,\n",
    "    references: list,\n",
    "    base_threshold: float = 0.70,\n",
    "    boost_per_hit: float = 0.02,   # í‚¤ì›Œë“œ 1ê°œë‹¹ ê°€ì‚°ì \n",
    "    penalty: float = 0.05,         # í‚¤ì›Œë“œê°€ í•˜ë‚˜ë„ ì—†ì„ ë•Œ ê°ì \n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    - MPNet ê¸°ë°˜ ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼ì—\n",
    "    - ë³´ìœ¡ í•µì‹¬ í‚¤ì›Œë“œ ì¶œí˜„ ê°œìˆ˜ì— ë”°ë¼ ì ìˆ˜ë¥¼ ë³´ì •.\n",
    "    \"\"\"\n",
    "    # ê¸°ë³¸ ë¶„ë¥˜ ê²°ê³¼\n",
    "    result = classifier.classify_childcare_document(image_path, references)\n",
    "\n",
    "    # ê¸°ë³¸ ìœ ì‚¬ë„ ì ìˆ˜(MPNet ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìµœëŒ“ê°’)\n",
    "    score = result[\"max_confidence\"]\n",
    "\n",
    "    # OCR ì›ë¬¸(OCRë¡œ ì½ì–´ë‚¸ ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸)\n",
    "    raw_text = result.get(\"raw_text\", \"\")\n",
    "\n",
    "    # í‚¤ì›Œë“œ ë“±ì¥ ê°œìˆ˜ ì„¸ê¸°\n",
    "    hit_count = sum(raw_text.count(kw) for kw in KEYWORDS)\n",
    "\n",
    "    # ì ìˆ˜ ê°€ì‚°/ê°ì‚°\n",
    "    if hit_count > 0:\n",
    "        score += boost_per_hit * hit_count\n",
    "    else:\n",
    "        score -= penalty\n",
    "\n",
    "    #ìµœì¢… íŒì •\n",
    "    verdict = score >= base_threshold\n",
    "\n",
    "    #ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€ ì •ë³´ ì €ì¥\n",
    "    result[\"rule_score\"] = round(score, 4)\n",
    "    result[\"verdict\"] = verdict\n",
    "    result[\"keyword_hit_count\"] = hit_count\n",
    "    result[\"base_threshold\"] = base_threshold\n",
    "    result[\"boost_per_hit\"] = boost_per_hit\n",
    "    result[\"penalty\"] = penalty\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ----------------- ì‚¬ìš© ì˜ˆì‹œ -----------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ë³´ìœ¡ ê´€ë ¨ ê¸°ì¤€ ë¬¸ì¥ ì˜ˆì‹œ\n",
    "    REFERENCES = [\n",
    "        # ê³µí†µ íƒ€ì´í‹€\n",
    "        \"ë³´ìœ¡êµì‚¬\",\n",
    "\n",
    "        # ë²•ì  ê·¼ê±° ë¬¸ì¥\n",
    "        \"ì˜ìœ ì•„ë³´ìœ¡ë²•ì— ë”°ë¼ ë³´ìœ¡êµì‚¬ì˜\",\n",
    "\n",
    "        # ê¸‰ìˆ˜Â·ì§ì¢… í‘œí˜„\n",
    "        \"ë³´ìœ¡êµì‚¬ 1ê¸‰\",\n",
    "        \"ë³´ìœ¡êµì‚¬ 2ê¸‰\",\n",
    "        \"ë³´ìœ¡êµì‚¬ 3ê¸‰\",\n",
    "\n",
    "        # êµì›ìê²©ì¦ ìª½(ë³´ìœ¡ê³¼ í—·ê°ˆë¦´ ìˆ˜ ìˆëŠ” êµìœ¡ë¶€ ì–‘ì‹ìš©)\n",
    "        \"êµì› ìê²©ì¦\",\n",
    "        \"êµìœ¡ë¶€ì¥ê´€\",\n",
    "    ]\n",
    "\n",
    "    classifier = ChildcareDocumentClassifier(similarity_threshold=0.70)\n",
    "\n",
    "    img_path = r\"C:\\Users\\ehjun\\Documents\\ìº¡ìŠ¤í†¤ë””ìì¸\\ìë™ë¬¸ì„œì¸ì‹ëª¨ë¸\\data\\ë³´ìœ¡ìê²©ì¦ ì•„ë‹Œê²ƒ\\í† ìµì„±ì .png\"\n",
    "\n",
    "    result = classify_childcare_with_rules(\n",
    "        classifier,\n",
    "        image_path=img_path,\n",
    "        references=REFERENCES,\n",
    "        base_threshold=0.70,\n",
    "        boost_per_hit=0.02,   # â† ì´ë¦„ ë³€ê²½\n",
    "        penalty=0.05,\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ¯ ìµœì¢… íŒì •:\", \"ë³´ìœ¡ ê´€ë ¨ ë¬¸ì„œ âœ…\" if result[\"verdict\"] else \"ì¼ë°˜ ë¬¸ì„œ âŒ\")\n",
    "    print(\"  - base similarity:\", result[\"max_confidence\"])\n",
    "    print(\"  - rule_score     :\", result[\"rule_score\"])\n",
    "    print(\"  - keyword hits   :\", result[\"keyword_hit_count\"])\n",
    "    print(\"  - matched sent   :\", result[\"matched_sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113571b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capston",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
